{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#FACE DETECTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter any positive  number10\n",
      "sum of number is 55\n"
     ]
    }
   ],
   "source": [
    "n=int(input(\"enter any positive  number\"))\n",
    "Sum=0\n",
    "for i in range(0,n+1):\n",
    "    Sum=Sum+i\n",
    "print(\"sum of number is\",Sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b1e2976a0dfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.pinterest.co.uk/pin/499055202453818324/?autologin=true'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "from google.colab.patch import cv2_imshow\n",
    "import cv2\n",
    "img=cv2.imread('https://www.pinterest.co.uk/pin/499055202453818324/?autologin=true')\n",
    "print(cv2_imshow(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.3.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8ca7c6868a6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Read the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Detect faces in the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.3.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "# Get user supplied values\n",
    "imagePath = sys.argv[1]\n",
    "cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the image\n",
    "faces = faceCascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=5,\n",
    "    minSize=(30, 30),\n",
    "    flags = cv2.cv.CV_HAAR_SCALE_IMAGE\n",
    ")\n",
    "\n",
    "print(\"Found {0} faces!\".format(len(faces)))\n",
    "\n",
    "# Draw a rectangle around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Faces found\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk \n",
    "from tkinter import Message, Text \n",
    "import cv2 \n",
    "import os \n",
    "import shutil \n",
    "import csv \n",
    "import numpy as np \n",
    "from PIL import Image, ImageTk \n",
    "import pandas as pd \n",
    "import datetime \n",
    "import time \n",
    "import tkinter.ttk as ttk \n",
    "import tkinter.font as font \n",
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = tk.Tk()  \n",
    "window.title(\"Face_Recogniser\") \n",
    "window.configure(background ='white') \n",
    "window.grid_rowconfigure(0, weight = 1) \n",
    "window.grid_columnconfigure(0, weight = 1) \n",
    "message = tk.Label( \n",
    "    window, text =\"Face-Recognition-System\",  \n",
    "    bg =\"green\", fg = \"white\", width = 50,  \n",
    "    height = 3, font = ('times', 30, 'bold'))  \n",
    "      \n",
    "message.place(x = 200, y = 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = tk.Label(window, text = \"No.\",  \n",
    "width = 20, height = 2, fg =\"green\",  \n",
    "bg = \"white\", font = ('times', 15, ' bold ') )  \n",
    "lbl.place(x = 400, y = 200) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = tk.Entry(window,  \n",
    "width = 20, bg =\"white\",  \n",
    "fg =\"green\", font = ('times', 15, ' bold ')) \n",
    "txt.place(x = 700, y = 215) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl2 = tk.Label(window, text =\"Name\",  \n",
    "width = 20, fg =\"green\", bg =\"white\",  \n",
    "height = 2, font =('times', 15, ' bold '))  \n",
    "lbl2.place(x = 400, y = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt2 = tk.Entry(window, width = 20,  \n",
    "bg =\"white\", fg =\"green\",  \n",
    "font = ('times', 15, ' bold ')  ) \n",
    "txt2.place(x = 700, y = 315) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric()\n",
    "        return True\n",
    "    except (TypeError,ValueError):\n",
    "        pass\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TakeImages():\n",
    "    Id=(txt.get())\n",
    "    name=(txt2.get())\n",
    "    \n",
    "    if (is_number(Id) and name.is_alpha()):\n",
    "        cam = cv2.VideoCapture(0) \n",
    "        harcascadePath = \"data\\haarcascade_frontalface_default.xml\" \n",
    "        detector = cv2.CascadeClassifier(harcascadePath) \n",
    "        sampleNum = 0 \n",
    "        \n",
    "        while (True):\n",
    "            ret, img = cam.read()\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "            faces = detector.detectMultiScale(gray, 1.3, 5) \n",
    "            \n",
    "            for (x, y, w, h) in faces:  \n",
    "                cv2.rectangle(img, (x, y), ( \n",
    "                    x + w, y + h), (255, 0, 0), 2)  \n",
    "                sampleNum = sampleNum + 1\n",
    "                \n",
    "                cv2.imwrite( \n",
    "                    \"TrainingImage\\ \"+name +\".\"+Id +'.'+ str( \n",
    "                        sampleNum) + \".jpg\", gray[y:y + h, x:x + w])\n",
    "                cv2.imshow('frame', img)\n",
    "                \n",
    "            if cv2.waitKey(100) & 0xFF == ord('q'): \n",
    "                break\n",
    "                \n",
    "            elif sampleNum>60: \n",
    "                break\n",
    "                \n",
    "        cam.release()  \n",
    "        cv2.destroyAllWindows() \n",
    "        res = \"Images Saved for ID : \" + Id +\" Name : \"+ name \n",
    "    \n",
    "        row = [Id, name]  \n",
    "        with open('UserDetails.csv', 'a+') as csvFile: \n",
    "            writer = csv.writer(csvFile) \n",
    "        # Entry of the row in csv file \n",
    "            writer.writerow(row)  \n",
    "        csvFile.close() \n",
    "        message.configure(text = res) \n",
    "  \n",
    "    else: \n",
    "        if(is_number(Id)): \n",
    "            res = \"Enter Alphabetical Name\"\n",
    "            message.configure(text = res) \n",
    "        if(name.isalpha()): \n",
    "            res = \"Enter Numeric Id\"\n",
    "            message.configure(text = res) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainImages():\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create() \n",
    "    harcascadePath = \"data\\haarcascade_frontalface_default.xml\"\n",
    "    detector = cv2.CascadeClassifier(harcascadePath)\n",
    "    faces, Id = getImagesAndLabels(\"TrainingImage\")\n",
    "    recognizer.train(faces, np.array(Id))      \n",
    "    recognizer.save(\"TrainingImageLabel\\Trainner.yml\")  \n",
    "    res = \"Image Trained\" \n",
    "    message.configure(text = res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImagesAndLabels(path): \n",
    "    # get the path of all the files in the folder \n",
    "    imagePaths =[os.path.join(path, f) for f in os.listdir(path)]  \n",
    "    faces =[] \n",
    "    # creating empty ID list \n",
    "    Ids =[] \n",
    "    # now looping through all the image paths and loading the \n",
    "    # Ids and the images saved in the folder \n",
    "    for imagePath in imagePaths: \n",
    "        # loading the image and converting it to gray scale \n",
    "        pilImage = Image.open(imagePath).convert('L') \n",
    "        # Now we are converting the PIL image into numpy array \n",
    "        imageNp = np.array(pilImage, 'uint8') \n",
    "        # getting the Id from the image \n",
    "        Id = int(os.path.split(imagePath)[-1].split(\".\")[1]) \n",
    "        # extract the face from the training image sample \n",
    "        faces.append(imageNp) \n",
    "        Ids.append(Id)         \n",
    "    return faces, Ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrackImages(): \n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create() \n",
    "    # Reading the trained model \n",
    "    recognizer.read(\"TrainingImageLabel\\Trainner.yml\")  \n",
    "    harcascadePath = \"data\\haarcascade_frontalface_default.xml\"\n",
    "    faceCascade = cv2.CascadeClassifier(harcascadePath) \n",
    "    # getting the name from \"userdetails.csv\" \n",
    "    df = pd.read_csv(\"UserDetails.csv\")   \n",
    "    cam = cv2.VideoCapture(0) \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX         \n",
    "    while True: \n",
    "        ret, im = cam.read() \n",
    "        gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) \n",
    "        faces = faceCascade.detectMultiScale(gray, 1.2, 5)     \n",
    "        for(x, y, w, h) in faces: \n",
    "            cv2.rectangle(im, (x, y), (x + w, y + h), (225, 0, 0), 2) \n",
    "            Id, conf = recognizer.predict(gray[y:y + h, x:x + w])                                    \n",
    "            if(conf < 50): \n",
    "                aa = df.loc[df['Id'] == Id]['Name'].values \n",
    "                tt = str(Id)+\"-\"+aa     \n",
    "            else: \n",
    "                Id ='Unknown'                \n",
    "                tt = str(Id)   \n",
    "            if(conf > 75): \n",
    "                noOfFile = len(os.listdir(\"ImagesUnknown\"))+1\n",
    "                cv2.imwrite(\"ImagesUnknown\\Image\"+ \n",
    "                str(noOfFile) + \".jpg\", im[y:y + h, x:x + w])             \n",
    "            cv2.putText(im, str(tt), (x, y + h),  \n",
    "            font, 1, (255, 255, 255), 2)         \n",
    "        cv2.imshow('im', im)  \n",
    "        if (cv2.waitKey(1)== ord('q')): \n",
    "            break\n",
    "    cam.release() \n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "takeImg = tk.Button(window, text =\"Sample\",  \n",
    "command = TakeImages, fg =\"white\", bg =\"green\",  \n",
    "width = 20, height = 3, activebackground = \"Red\",  \n",
    "font =('times', 15, ' bold ')) \n",
    "takeImg.place(x = 200, y = 500) \n",
    "trainImg = tk.Button(window, text =\"Training\",  \n",
    "command = TrainImages, fg =\"white\", bg =\"green\",  \n",
    "width = 20, height = 3, activebackground = \"Red\",  \n",
    "font =('times', 15, ' bold ')) \n",
    "trainImg.place(x = 500, y = 500) \n",
    "trackImg = tk.Button(window, text =\"Testing\",  \n",
    "command = TrackImages, fg =\"white\", bg =\"green\",  \n",
    "width = 20, height = 3, activebackground = \"Red\",  \n",
    "font =('times', 15, ' bold ')) \n",
    "trackImg.place(x = 800, y = 500) \n",
    "quitWindow = tk.Button(window, text =\"Quit\",  \n",
    "command = window.destroy, fg =\"white\", bg =\"green\",  \n",
    "width = 20, height = 3, activebackground = \"Red\",  \n",
    "font =('times', 15, ' bold ')) \n",
    "quitWindow.place(x = 1100, y = 500) \n",
    "  \n",
    "window.mainloop()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
